{
  "best_model": {
    "name": "Voting Classifier (Hard)",
    "accuracy": 0.75,
    "results": {
      "accuracy": 0.75,
      "roc_auc": null,
      "cv_mean": 0.7502164502164502,
      "cv_std": 0.019145752716446713
    }
  },
  "model_performance": {
    "Voting Classifier (Hard)": {
      "accuracy": 0.75,
      "roc_auc": null,
      "cv_mean": 0.7502164502164502,
      "cv_std": 0.019145752716446713
    },
    "Voting Classifier (Soft)": {
      "accuracy": 0.75,
      "roc_auc": 0.034013605442176874,
      "cv_mean": 0.7502164502164502,
      "cv_std": 0.019145752716446713
    },
    "Bagging Ensemble": {
      "accuracy": 0.5357142857142857,
      "roc_auc": 0.006802721088435376,
      "cv_mean": 0.6017316017316017,
      "cv_std": 0.0751677720960404
    },
    "AdaBoost Ensemble": {
      "accuracy": 0.42857142857142855,
      "roc_auc": 0.21428571428571427,
      "cv_mean": 0.4424242424242424,
      "cv_std": 0.0950568917658068
    }
  },
  "recommendations": [
    "Best performing ensemble: Voting Classifier (Hard) with 0.7500 accuracy",
    "Ensemble methods show improved performance over individual models",
    "Consider combining with deep learning models for further improvement",
    "Feature engineering and hyperparameter tuning may boost performance"
  ]
}
#!/usr/bin/env python3
"""
Streamlit Application for Tampered Image Detection
Uses the best performing model (LightGBM with SMOTE+ENN) from Objective 2
"""

import streamlit as st
import numpy as np
import pandas as pd
import joblib
import os
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import json
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# Try to import OpenCV with fallback handling for deployment
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    # Try headless version for deployment environments
    try:
        import cv2
        CV2_AVAILABLE = True
    except ImportError:
        CV2_AVAILABLE = False
        st.error("‚ö†Ô∏è OpenCV not available. Some features may be limited.")
        st.info("Please ensure opencv-python-headless is installed: pip install opencv-python-headless")

# Import our custom feature extraction classes
import sys
# Add current directory to path for deployment compatibility
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

class TamperedImageDetector:
    """Main class for tampered image detection using the best model"""
    
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_extractor = None
        self.feature_indices = None
        self.is_loaded = False
        
    def load_model(self):
        """Load the best performing model and preprocessing components"""
        try:
            # Load the robust ensemble model (much better performance on original images)
            model_path = 'objective2_robust_models/ensemble_robust.joblib'
            if os.path.exists(model_path):
                self.model = joblib.load(model_path)
                st.success("‚úÖ Loaded robust ensemble model (83.3% overall accuracy)")
            else:
                # Fallback to baseline model
                model_path = 'objective2_baseline_models/lightgbm.joblib'
                if os.path.exists(model_path):
                    self.model = joblib.load(model_path)
                    st.warning("‚ö†Ô∏è Using baseline model (biased towards tampered)")
                else:
                    st.error("‚ùå No model found")
                    return False
            
            # Load scaler
            scaler_path = 'objective2_robust_models/scaler_robust.joblib'
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
            else:
                # Fallback to baseline scaler
                scaler_path = 'objective2_baseline_models/scaler.joblib'
                if os.path.exists(scaler_path):
                    self.scaler = joblib.load(scaler_path)
            
            # Load feature indices
            feature_info_path = 'objective2_robust_models/feature_info_robust.json'
            if os.path.exists(feature_info_path):
                with open(feature_info_path, 'r') as f:
                    feature_info = json.load(f)
                    self.feature_indices = feature_info.get('selected_features', list(range(105)))
            else:
                # Fallback to baseline feature info
                feature_info_path = 'objective2_baseline_models/feature_info.json'
                if os.path.exists(feature_info_path):
                    with open(feature_info_path, 'r') as f:
                        feature_info = json.load(f)
                        self.feature_indices = feature_info.get('selected_features', list(range(105)))
            
            # Initialize feature extractor
            if CV2_AVAILABLE:
                from objective2_feature_extraction import ForensicFeatureExtractor
                self.feature_extractor = ForensicFeatureExtractor(target_size=(224, 224))
            else:
                st.error("Cannot initialize feature extractor without OpenCV")
                return False
            
            self.is_loaded = True
            return True
            
        except Exception as e:
            st.error(f"Error loading model: {e}")
            return False
    
    def extract_features(self, image_path):
        """Extract features from an image"""
        try:
            features = self.feature_extractor.extract_all_features(image_path)
            
            # Convert to array and select relevant features
            feature_cols = [col for col in features.keys() if col not in ['image_path', 'label', 'tamper_type', 'category']]
            feature_values = [features[col] for col in feature_cols]
            feature_array = np.array(feature_values).reshape(1, -1)
            
            # Handle infinite and NaN values
            feature_array = np.nan_to_num(feature_array, nan=0.0, posinf=1e6, neginf=-1e6)
            
            return feature_array
            
        except Exception as e:
            st.error(f"Error extracting features: {e}")
            return None
    
    def preprocess_features(self, features):
        """Preprocess features using the same pipeline as training"""
        try:
            # Select the exact same features used during training first
            if self.feature_indices:
                # Use the exact feature indices from training
                features_selected = features[:, self.feature_indices]
            else:
                # Fallback: use first 30 features if indices not available
                features_selected = features[:, :30]
            
            # Apply robust scaling
            if self.scaler:
                features_scaled = self.scaler.transform(features_selected)
            else:
                features_scaled = features_selected
            
            return features_scaled
            
        except Exception as e:
            st.error(f"Error preprocessing features: {e}")
            return None
    
    def predict(self, image_path):
        """Make prediction on an image"""
        if not self.is_loaded:
            return None, None, None
        
        try:
            # Extract features
            features = self.extract_features(image_path)
            if features is None:
                return None, None, None
            
            # Preprocess features
            features_processed = self.preprocess_features(features)
            if features_processed is None:
                return None, None, None
            
            # Make prediction
            prediction = self.model.predict(features_processed)[0]
            probability = self.model.predict_proba(features_processed)[0]
            
            return prediction, probability, features_processed
            
        except Exception as e:
            st.error(f"Error making prediction: {e}")
            return None, None, None

def create_model_info_section():
    """Create model information section"""
    st.subheader("ü§ñ Model Information")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Model Type", "Robust Ensemble")
    
    with col2:
        st.metric("Overall Accuracy", "83.3%")
    
    with col3:
        st.metric("Features Used", "30")
    
    st.info("""
    **Model Details:**
    - **Algorithm**: Robust Ensemble combining 5 models (RandomForest, LightGBM, XGBoost, SVM, LogisticRegression)
    - **Ensemble Method**: Soft voting for probability-based predictions
    - **Preprocessing**: SMOTE+ENN for handling class imbalance
    - **Feature Selection**: 30 most relevant forensic features
    - **Training Data**: SUPATLANTIQUE dataset (136 images)
    - **Performance**: 83.3% overall accuracy with balanced performance
    """)
    
    # Performance metrics section
    st.subheader("üìä Performance Metrics")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Original Images", "66.7%", "Accuracy")
        st.caption("Correctly identifies original images")
    
    with col2:
        st.metric("Tampered Images", "100%", "Accuracy")
        st.caption("Perfect detection of tampered images")
    
    with col3:
        st.metric("Overall Performance", "83.3%", "Accuracy")
        st.caption("Balanced performance across both classes")
    
    # Ensemble method details
    st.subheader("üîß Ensemble Method Details")
    
    st.markdown("""
    **How the Robust Ensemble Works:**
    
    Our ensemble combines **5 different machine learning algorithms** using **soft voting**:
    
    1. **Random Forest** - Tree-based ensemble for robust feature selection
    2. **LightGBM** - Gradient boosting for high performance
    3. **XGBoost** - Advanced gradient boosting with regularization
    4. **SVM (RBF)** - Support Vector Machine for non-linear patterns
    5. **Logistic Regression** - Linear baseline for interpretability
    
    **Ensemble Strategy:**
    - Each model makes individual predictions
    - **Soft voting** combines probability scores from all models
    - Final prediction based on averaged probabilities
    - **SMOTE+ENN** preprocessing ensures balanced training data
    
    **Why This Works Better:**
    - Reduces overfitting by combining diverse algorithms
    - Handles class imbalance through proper preprocessing
    - More robust predictions than any single model
    - Better generalization to new images
    """)

def create_upload_section():
    """Create file upload section"""
    st.subheader("üìÅ Upload Image")
    
    uploaded_file = st.file_uploader(
        "Choose an image file",
        type=['jpg', 'jpeg', 'png', 'tiff', 'tif'],
        help="Upload an image to detect if it's tampered or original"
    )
    
    return uploaded_file

def create_prediction_section(detector, uploaded_file):
    """Create prediction results section"""
    if uploaded_file is not None:
        st.subheader("üîç Analysis Results")
        
        # Save uploaded file temporarily
        temp_path = f"temp_{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        try:
            # Display uploaded image
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üì∏ Uploaded Image")
                image = Image.open(uploaded_file)
                st.image(image, caption="Uploaded Image", use_column_width=True)
                
                # Image info
                st.write(f"**Image Info:**")
                st.write(f"- Format: {image.format}")
                st.write(f"- Size: {image.size}")
                st.write(f"- Mode: {image.mode}")
            
            with col2:
                st.subheader("üéØ Detection Results")
                
                # Make prediction
                with st.spinner("Analyzing image..."):
                    prediction, probability, features = detector.predict(temp_path)
                
                if prediction is not None:
                    # Display results
                    if prediction == 1:
                        st.error("üö® **TAMPERED IMAGE DETECTED**")
                        st.write("The model has detected signs of tampering in this image.")
                    else:
                        st.success("‚úÖ **ORIGINAL IMAGE**")
                        st.write("The model has determined this image appears to be original.")
                    
                    # Confidence scores
                    st.write("**Confidence Scores:**")
                    col_conf1, col_conf2 = st.columns(2)
                    
                    with col_conf1:
                        st.metric(
                            "Original", 
                            f"{probability[0]*100:.1f}%",
                            delta=f"{probability[0]*100-50:.1f}%"
                        )
                    
                    with col_conf2:
                        st.metric(
                            "Tampered", 
                            f"{probability[1]*100:.1f}%",
                            delta=f"{probability[1]*100-50:.1f}%"
                        )
                    
                    # Confidence bar
                    st.write("**Confidence Visualization:**")
                    fig, ax = plt.subplots(figsize=(8, 2))
                    ax.barh(['Original', 'Tampered'], [probability[0], probability[1]], 
                           color=['green', 'red'], alpha=0.7)
                    ax.set_xlim(0, 1)
                    ax.set_xlabel('Confidence')
                    ax.set_title('Prediction Confidence')
                    st.pyplot(fig)
                    
                    # Feature analysis
                    if features is not None:
                        st.write("**Feature Analysis:**")
                        st.write(f"Extracted {features.shape[1]} selected forensic features")
                        
                        # Show feature importance (simplified)
                        if detector.feature_indices:
                            feature_names = [f"Feature_{idx}" for idx in detector.feature_indices]
                        else:
                            feature_names = [f"Feature_{i}" for i in range(features.shape[1])]
                        
                        feature_df = pd.DataFrame({
                            'Feature': feature_names,
                            'Value': features[0]
                        })
                        
                        st.dataframe(feature_df.head(10), use_container_width=True)
                
                else:
                    st.error("Failed to analyze the image. Please try again.")
        
        finally:
            # Clean up temporary file
            if os.path.exists(temp_path):
                os.remove(temp_path)

def create_sample_images_section():
    """Create sample images section for testing"""
    st.subheader("üß™ Test with Sample Images")
    
    st.write("Test the model with sample images from the dataset:")
    
    # Sample images from the dataset
    sample_images = {
        "Original Image": "The SUPATLANTIQUE dataset/Tampered images/Original/s1_70.tif",
        "Copy-Move Tampered": "The SUPATLANTIQUE dataset/Tampered images/Tampered/Copy-move/s1_70_b.tif",
        "Retouching Tampered": "The SUPATLANTIQUE dataset/Tampered images/Tampered/Retouching/s1_70_c.tif",
        "Splicing Tampered": "The SUPATLANTIQUE dataset/Tampered images/Tampered/Splicing/s1_70_a.tif"
    }
    
    selected_sample = st.selectbox("Choose a sample image:", list(sample_images.keys()))
    
    if st.button("Test Sample Image"):
        sample_path = sample_images[selected_sample]
        if os.path.exists(sample_path):
            st.success(f"Testing with: {selected_sample}")
            return sample_path
        else:
            st.error("Sample image not found!")
    
    return None

def create_about_section():
    """Create about section"""
    st.subheader("‚ÑπÔ∏è About This Application")
    
    st.markdown("""
    ### Tampered Image Detection System
    
    This application uses advanced machine learning techniques to detect tampered images. 
    The system analyzes forensic features to determine if an image has been manipulated.
    
    #### How It Works:
    1. **Feature Extraction**: Extracts 105 forensic features including:
       - Error Level Analysis (ELA)
       - Noise analysis
       - Compression artifacts
       - Frequency domain features
       - Texture analysis
       - Statistical features
    
    2. **Preprocessing**: Applies robust scaling and feature selection
    
    3. **Prediction**: Uses Robust Ensemble model (5 algorithms) trained on SUPATLANTIQUE dataset
    
    #### Model Performance:
    - **Overall Accuracy**: 83.3% on test set
    - **Original Images**: 66.7% accuracy (correctly identifies original images)
    - **Tampered Images**: 100% accuracy (perfect detection of tampered images)
    - **Training Data**: 136 images (102 tampered, 34 original)
    - **Tampering Types**: Copy-move, Retouching, Splicing
    
    #### Limitations:
    - Model accuracy is limited by small training dataset
    - May not detect very sophisticated tampering
    - Results should be used as a preliminary analysis tool
    
    #### Dataset:
    - **SUPATLANTIQUE Dataset**: Professional tampering dataset
    - **High Resolution**: 2480x3500 pixel images
    - **Multiple Tampering Types**: Copy-move, retouching, splicing
    """)

def create_sidebar():
    """Create sidebar with additional information"""
    st.sidebar.title("üîß Settings")
    
    st.sidebar.subheader("Model Status")
    if st.session_state.get('model_loaded', False):
        st.sidebar.success("‚úÖ Model Loaded")
    else:
        st.sidebar.error("‚ùå Model Not Loaded")
    
    st.sidebar.subheader("Quick Stats")
    st.sidebar.metric("Overall Accuracy", "83.3%")
    st.sidebar.metric("Features", "30")
    st.sidebar.metric("Training Images", "136")
    
    st.sidebar.subheader("Navigation")
    page = st.sidebar.selectbox("Go to:", [
        "Main Detection",
        "Model Information", 
        "About",
        "Sample Testing"
    ])
    
    return page

def main():
    """Main Streamlit application"""
    st.set_page_config(
        page_title="Tampered Image Detection",
        page_icon="üîç",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Initialize session state
    if 'detector' not in st.session_state:
        st.session_state.detector = TamperedImageDetector()
        st.session_state.model_loaded = False
    
    # Load model
    if not st.session_state.model_loaded:
        with st.spinner("Loading model..."):
            st.session_state.model_loaded = st.session_state.detector.load_model()
    
    # Create sidebar
    page = create_sidebar()
    
    # Main title
    st.title("üîç Tampered Image Detection System")
    st.markdown("**Advanced Forensic Image Analysis using Machine Learning**")
    
    # Main content based on page selection
    if page == "Main Detection":
        # Model info
        create_model_info_section()
        
        st.divider()
        
        # File upload
        uploaded_file = create_upload_section()
        
        # Prediction
        if uploaded_file is not None:
            create_prediction_section(st.session_state.detector, uploaded_file)
    
    elif page == "Model Information":
        create_model_info_section()
        
        st.divider()
        
        # Additional model details
        st.subheader("üìä Model Performance Details")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Training Results:**")
            results_data = {
                'Model': ['LightGBM + SMOTE+ENN', 'XGBoost Original', 'SVM + SMOTE'],
                'Accuracy': [75.0, 46.4, 42.9],
                'ROC AUC': [50.0, 2.4, 21.8]
            }
            st.dataframe(pd.DataFrame(results_data), use_container_width=True)
        
        with col2:
            st.write("**Feature Categories:**")
            features = {
                'Category': ['ELA Features', 'Noise Analysis', 'Compression', 'Frequency', 'Texture', 'Statistical'],
                'Count': [5, 5, 8, 5, 8, 15]
            }
            st.dataframe(pd.DataFrame(features), use_container_width=True)
    
    elif page == "Sample Testing":
        st.subheader("üß™ Sample Image Testing")
        sample_path = create_sample_images_section()
        
        if sample_path:
            create_prediction_section(st.session_state.detector, sample_path)
    
    elif page == "About":
        create_about_section()
    
    # Footer
    st.divider()
    st.markdown("""
    <div style='text-align: center; color: gray;'>
        <p>Tampered Image Detection System | Objective 2 - AI TraceFinder Project</p>
        <p>Model: Robust Ensemble | Overall Accuracy: 83.3% | Features: 30</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()

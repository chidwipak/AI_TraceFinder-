import streamlit as st
import numpy as np
import pandas as pd
import joblib
import os
from PIL import Image
import cv2
import json
from scipy import ndimage
from scipy.stats import skew, kurtosis
from scipy.fft import fft2, fftshift
from skimage import filters, feature, measure
from skimage.filters import gabor
import pywt
import mahotas as mh
import warnings
warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="AI TraceFinder - Tampered Image Detection",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #2E86AB;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #A23B72;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class TamperedImageDetector:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_indices = None
        self.load_model()
    
    def load_model(self):
        """Load the robust ensemble model and scaler"""
        try:
            # Try to load the robust ensemble model
            model_path = 'objective2_robust_models/ensemble_robust.joblib'
            if os.path.exists(model_path):
                self.model = joblib.load(model_path)
                st.success("‚úÖ Loaded robust ensemble model (83.3% overall accuracy)")
            else:
                # Fallback to baseline model
                model_path = 'objective2_baseline_models/lightgbm.joblib'
                if os.path.exists(model_path):
                    self.model = joblib.load(model_path)
                    st.success("‚úÖ Loaded baseline LightGBM model (75% accuracy)")
                else:
                    st.error("‚ùå No model found. Please ensure model files are available.")
                    return
            
            # Load scaler
            scaler_path = 'objective2_robust_models/scaler_robust.joblib'
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
            else:
                scaler_path = 'objective2_baseline_models/scaler.joblib'
                if os.path.exists(scaler_path):
                    self.scaler = joblib.load(scaler_path)
            
            # Load feature info
            feature_info_path = 'objective2_robust_models/feature_info_robust.json'
            if os.path.exists(feature_info_path):
                with open(feature_info_path, 'r') as f:
                    feature_info = json.load(f)
                    self.feature_indices = feature_info.get('selected_features', [])
            else:
                feature_info_path = 'objective2_baseline_models/feature_info.json'
                if os.path.exists(feature_info_path):
                    with open(feature_info_path, 'r') as f:
                        feature_info = json.load(f)
                        self.feature_indices = feature_info.get('selected_features', [])
            
        except Exception as e:
            st.error(f"‚ùå Error loading model: {str(e)}")
    
    def extract_ela_features(self, image):
        """Extract Error Level Analysis features"""
        try:
            # Convert to grayscale
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Save and reload with JPEG compression
            temp_path = '/tmp/temp_image.jpg'
            cv2.imwrite(temp_path, gray, [cv2.IMWRITE_JPEG_QUALITY, 90])
            compressed = cv2.imread(temp_path, cv2.IMREAD_GRAYSCALE)
            os.remove(temp_path)
            
            # Calculate ELA
            ela = np.abs(gray.astype(np.float32) - compressed.astype(np.float32))
            
            features = [
                np.mean(ela),
                np.std(ela),
                np.max(ela),
                np.min(ela),
                np.median(ela),
                np.var(ela),
                skew(ela.flatten()),
                kurtosis(ela.flatten())
            ]
            
            return features
        except Exception as e:
            return [0.0] * 8
    
    def extract_noise_features(self, image):
        """Extract noise analysis features"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Apply different filters
            gaussian = cv2.GaussianBlur(gray, (5, 5), 0)
            median = cv2.medianBlur(gray, 5)
            bilateral = cv2.bilateralFilter(gray, 9, 75, 75)
            
            # Calculate noise residuals
            noise_gaussian = gray.astype(np.float32) - gaussian.astype(np.float32)
            noise_median = gray.astype(np.float32) - median.astype(np.float32)
            noise_bilateral = gray.astype(np.float32) - bilateral.astype(np.float32)
            
            features = [
                np.mean(noise_gaussian),
                np.std(noise_gaussian),
                np.mean(noise_median),
                np.std(noise_median),
                np.mean(noise_bilateral),
                np.std(noise_bilateral),
                np.var(noise_gaussian),
                np.var(noise_median),
                np.var(noise_bilateral),
                np.max(noise_gaussian),
                np.max(noise_median),
                np.max(noise_bilateral)
            ]
            
            return features
        except Exception as e:
            return [0.0] * 12
    
    def extract_compression_features(self, image):
        """Extract compression artifact features"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # DCT analysis
            dct = cv2.dct(gray.astype(np.float32))
            
            # Block artifacts detection
            block_size = 8
            artifacts = []
            for i in range(0, gray.shape[0] - block_size, block_size):
                for j in range(0, gray.shape[1] - block_size, block_size):
                    block = gray[i:i+block_size, j:j+block_size]
                    artifacts.append(np.std(block))
            
            features = [
                np.mean(dct),
                np.std(dct),
                np.max(dct),
                np.min(dct),
                np.mean(artifacts),
                np.std(artifacts),
                np.max(artifacts),
                np.min(artifacts),
                np.var(artifacts),
                np.median(artifacts),
                skew(np.array(artifacts)),
                kurtosis(np.array(artifacts)),
                np.percentile(artifacts, 25),
                np.percentile(artifacts, 75),
                np.percentile(artifacts, 90)
            ]
            
            return features
        except Exception as e:
            return [0.0] * 15
    
    def extract_frequency_features(self, image):
        """Extract frequency domain features"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # FFT analysis
            f_transform = fft2(gray)
            f_shift = fftshift(f_transform)
            magnitude_spectrum = np.log(np.abs(f_shift) + 1)
            
            # DCT analysis
            dct = cv2.dct(gray.astype(np.float32))
            
            # Wavelet analysis
            coeffs = pywt.dwt2(gray, 'haar')
            cA, (cH, cV, cD) = coeffs
            
            features = [
                np.mean(magnitude_spectrum),
                np.std(magnitude_spectrum),
                np.max(magnitude_spectrum),
                np.min(magnitude_spectrum),
                np.var(magnitude_spectrum),
                np.median(magnitude_spectrum),
                np.mean(dct),
                np.std(dct),
                np.max(dct),
                np.min(dct),
                np.mean(cA),
                np.std(cA),
                np.mean(cH),
                np.std(cH),
                np.mean(cV),
                np.std(cV),
                np.mean(cD),
                np.std(cD),
                np.var(cA),
                np.var(cH)
            ]
            
            return features
        except Exception as e:
            return [0.0] * 20
    
    def extract_statistical_features(self, image):
        """Extract statistical features"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # Basic statistics
            features = [
                np.mean(gray),
                np.std(gray),
                np.var(gray),
                np.median(gray),
                np.min(gray),
                np.max(gray),
                skew(gray.flatten()),
                kurtosis(gray.flatten()),
                np.percentile(gray, 25),
                np.percentile(gray, 75),
                np.percentile(gray, 90),
                np.percentile(gray, 95),
                np.percentile(gray, 99),
                np.percentile(gray, 1),
                np.percentile(gray, 5),
                np.percentile(gray, 10),
                np.percentile(gray, 20),
                np.percentile(gray, 30),
                np.percentile(gray, 40),
                np.percentile(gray, 50),
                np.percentile(gray, 60),
                np.percentile(gray, 70),
                np.percentile(gray, 80),
                np.percentile(gray, 85),
                np.percentile(gray, 90)
            ]
            
            return features
        except Exception as e:
            return [0.0] * 25
    
    def extract_texture_features(self, image):
        """Extract texture features"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            
            # GLCM features
            glcm = feature.graycomatrix(gray, distances=[1], angles=[0, 45, 90, 135], levels=256, symmetric=True, normed=True)
            
            # Haralick features
            contrast = feature.graycoprops(glcm, 'contrast')
            dissimilarity = feature.graycoprops(glcm, 'dissimilarity')
            homogeneity = feature.graycoprops(glcm, 'homogeneity')
            energy = feature.graycoprops(glcm, 'energy')
            correlation = feature.graycoprops(glcm, 'correlation')
            
            # LBP features
            lbp = feature.local_binary_pattern(gray, 8, 1, method='uniform')
            lbp_hist, _ = np.histogram(lbp.ravel(), bins=10, range=(0, 10))
            lbp_hist = lbp_hist.astype(float)
            lbp_hist /= (lbp_hist.sum() + 1e-7)
            
            # Zernike moments
            zernike_moments = mh.features.zernike_moments(gray, radius=8, degree=8)
            
            # Hu moments
            moments = cv2.moments(gray)
            hu_moments = cv2.HuMoments(moments).flatten()
            
            features = [
                np.mean(contrast),
                np.std(contrast),
                np.mean(dissimilarity),
                np.std(dissimilarity),
                np.mean(homogeneity),
                np.std(homogeneity),
                np.mean(energy),
                np.std(energy),
                np.mean(correlation),
                np.std(correlation),
                np.mean(lbp_hist),
                np.std(lbp_hist),
                np.max(lbp_hist),
                np.min(lbp_hist),
                np.var(lbp_hist),
                np.median(lbp_hist),
                np.mean(zernike_moments),
                np.std(zernike_moments),
                np.max(zernike_moments),
                np.min(zernike_moments),
                np.var(zernike_moments),
                np.median(zernike_moments),
                np.mean(hu_moments),
                np.std(hu_moments),
                np.max(hu_moments)
            ]
            
            return features
        except Exception as e:
            return [0.0] * 25
    
    def extract_all_features(self, image):
        """Extract all 105 forensic features from an image"""
        try:
            # Convert PIL to OpenCV format
            if isinstance(image, Image.Image):
                image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # Resize image
            image = cv2.resize(image, (224, 224))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Extract all feature categories
            features = []
            features.extend(self.extract_ela_features(image))  # 8 features
            features.extend(self.extract_noise_features(image))  # 12 features
            features.extend(self.extract_compression_features(image))  # 15 features
            features.extend(self.extract_frequency_features(image))  # 20 features
            features.extend(self.extract_statistical_features(image))  # 25 features
            features.extend(self.extract_texture_features(image))  # 25 features
            
            # Ensure we have exactly 105 features
            while len(features) < 105:
                features.append(0.0)
            features = features[:105]
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            st.error(f"Error extracting features: {str(e)}")
            return None
    
    def preprocess_features(self, features):
        """Preprocess features for model prediction"""
        try:
            if self.scaler:
                features_scaled = self.scaler.transform(features)
            else:
                features_scaled = features
            
            return features_scaled
        except Exception as e:
            st.error(f"Error preprocessing features: {str(e)}")
            return None
    
    def predict(self, image):
        """Make prediction on uploaded image"""
        try:
            if self.model is None:
                return None, "Model not loaded"
            
            # Extract all 105 features
            features = self.extract_all_features(image)
            if features is None:
                return None, "Feature extraction failed"
            
            # Preprocess features
            features_processed = self.preprocess_features(features)
            if features_processed is None:
                return None, "Feature preprocessing failed"
            
            # Make prediction
            prediction = self.model.predict(features_processed)[0]
            probability = self.model.predict_proba(features_processed)[0]
            
            # Get confidence
            confidence = max(probability) * 100
            
            return prediction, confidence
            
        except Exception as e:
            return None, f"Prediction error: {str(e)}"

def create_header():
    """Create the main header"""
    st.markdown('<h1 class="main-header">üîç AI TraceFinder</h1>', unsafe_allow_html=True)
    st.markdown('<h2 class="sub-header">Tampered Image Detection System</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <strong>Welcome to AI TraceFinder!</strong><br>
    This system uses advanced forensic analysis to detect tampered vs original images with 83.3% overall accuracy.
    <strong>Note:</strong> For best results, upload TIFF images as the model was trained on TIFF format from the SUPATLANTIQUE dataset.
    Upload an image below to get started with tampering detection.
    </div>
    """, unsafe_allow_html=True)

def create_model_info_section():
    """Create model information section"""
    st.markdown('<h3 class="sub-header">üìä Model Information</h3>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Model Type", "Robust Ensemble")
        st.metric("Overall Accuracy", "83.3%")
    
    with col2:
        st.metric("Tampered Images", "100% Accuracy")
        st.metric("Original Images", "66.7% Accuracy")
    
    with col3:
        st.metric("Features Used", "105")
        st.metric("Ensemble Method", "Soft Voting")
    
    st.markdown("""
    <div class="info-box">
    <strong>Model Details:</strong><br>
    ‚Ä¢ <strong>Algorithm</strong>: Robust Ensemble combining 5 models (RandomForest, LightGBM, XGBoost, SVM, LogisticRegression)<br>
    ‚Ä¢ <strong>Ensemble Method</strong>: Soft voting for probability-based predictions<br>
    ‚Ä¢ <strong>Class Balancing</strong>: SMOTE+ENN for improved original image detection<br>
    ‚Ä¢ <strong>Feature Selection</strong>: 105 comprehensive forensic features<br>
    ‚Ä¢ <strong>Performance</strong>: 83.3% overall accuracy with balanced performance
    </div>
    """, unsafe_allow_html=True)

def create_upload_section():
    """Create image upload section"""
    st.markdown('<h3 class="sub-header">üì§ Upload Image for Analysis</h3>', unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "Choose an image file",
        type=['tiff', 'tif', 'png', 'jpg', 'jpeg'],
        help="Upload a TIFF, PNG, JPG, or JPEG image for tampering detection (TIFF recommended for best accuracy)"
    )
    
    return uploaded_file

def create_prediction_section(detector, uploaded_file):
    """Create prediction results section"""
    if uploaded_file is not None:
        try:
            # Load and display image
            image = Image.open(uploaded_file)
            
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.markdown("**Uploaded Image:**")
                st.image(image, caption="Image to analyze", use_column_width=True)
            
            with col2:
                st.markdown("**Analysis Results:**")
                
                # Make prediction
                with st.spinner("Analyzing image..."):
                    prediction, confidence = detector.predict(image)
                
                if prediction is not None:
                    # Display results
                    if prediction == 1:
                        st.markdown("""
                        <div class="success-box">
                        <h4>üî¥ TAMPERED IMAGE DETECTED</h4>
                        <p><strong>Confidence:</strong> {:.1f}%</p>
                        <p>This image shows signs of tampering or manipulation.</p>
                        </div>
                        """.format(confidence), unsafe_allow_html=True)
                    else:
                        st.markdown("""
                        <div class="success-box">
                        <h4>üü¢ ORIGINAL IMAGE DETECTED</h4>
                        <p><strong>Confidence:</strong> {:.1f}%</p>
                        <p>This image appears to be original without tampering.</p>
                        </div>
                        """.format(confidence), unsafe_allow_html=True)
                    
                    # Confidence bar
                    st.progress(confidence / 100)
                    st.caption(f"Confidence: {confidence:.1f}%")
                    
                else:
                    st.error(f"‚ùå {confidence}")
        
        except Exception as e:
            st.error(f"Error processing image: {str(e)}")

def create_sidebar():
    """Create sidebar with additional information"""
    with st.sidebar:
        st.markdown("## üîß System Information")
        
        st.markdown("""
        **Model Performance:**
        - Overall Accuracy: 83.3%
        - Tampered Detection: 100%
        - Original Detection: 66.7%
        """)
        
        st.markdown("""
        **Supported Formats:**
        - TIFF/TIF (Recommended)
        - PNG
        - JPG/JPEG
        - Maximum size: 10MB
        """)
        
        st.markdown("""
        **Forensic Features:**
        - Error Level Analysis
        - Noise Pattern Analysis
        - Compression Artifacts
        - Frequency Domain Features
        - Statistical Measures
        - Texture Analysis
        """)
        
        st.markdown("---")
        st.markdown("**About AI TraceFinder**")
        st.markdown("""
        This system uses advanced machine learning and forensic analysis techniques to detect image tampering with high accuracy.
        """)

def create_footer():
    """Create footer"""
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; margin-top: 2rem;">
    <p><strong>AI TraceFinder</strong> - Advanced Forensic Image Analysis</p>
    <p>Powered by Robust Ensemble Machine Learning | 83.3% Accuracy</p>
    </div>
    """, unsafe_allow_html=True)

def main():
    """Main application function"""
    # Initialize detector
    detector = TamperedImageDetector()
    
    # Create UI components
    create_header()
    create_model_info_section()
    
    # Main content
    uploaded_file = create_upload_section()
    create_prediction_section(detector, uploaded_file)
    
    # Sidebar and footer
    create_sidebar()
    create_footer()

if __name__ == "__main__":
    main()
